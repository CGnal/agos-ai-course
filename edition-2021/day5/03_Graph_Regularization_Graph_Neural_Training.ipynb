{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "id-mrYUVxUd2"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/CGnal/agos-ai-course/blob/day5/day5/03_Graph_Regularization_Graph_Neural_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\\\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xjFz2htR61Wb",
    "outputId": "fea44176-74d7-4913-db46-9c4a602ed650"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets==7.6.5 in /usr/local/lib/python3.7/dist-packages (7.6.5)\n",
      "Requirement already satisfied: networkx==2.4 in /usr/local/lib/python3.7/dist-packages (2.4)\n",
      "Requirement already satisfied: matplotlib==3.2.2 in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
      "Requirement already satisfied: scikit-learn==0.24.0 in /usr/local/lib/python3.7/dist-packages (0.24.0)\n",
      "Requirement already satisfied: pandas==1.1.3 in /usr/local/lib/python3.7/dist-packages (1.1.3)\n",
      "Requirement already satisfied: numpy==1.19.2 in /usr/local/lib/python3.7/dist-packages (1.19.2)\n",
      "Requirement already satisfied: tensorflow==2.4.1 in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
      "Requirement already satisfied: neural-structured-learning==1.3.1 in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
      "Requirement already satisfied: stellargraph==1.2.1 in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets==7.6.5) (4.10.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets==7.6.5) (0.2.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets==7.6.5) (5.5.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets==7.6.5) (3.5.2)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets==7.6.5) (1.0.2)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets==7.6.5) (5.1.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets==7.6.5) (5.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx==2.4) (4.4.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2) (3.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2) (1.3.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.0) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.0) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.0) (3.0.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.3) (2018.9)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.17.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.32.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.2.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.7.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.4.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.10.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.37.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.2)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.12.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.7.4.3)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.3.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.12.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.12)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from neural-structured-learning==1.3.1) (21.2.0)\n",
      "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from stellargraph==1.2.1) (3.6.0)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->stellargraph==1.2.1) (5.2.1)\n",
      "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets==7.6.5) (5.1.1)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets==7.6.5) (5.3.5)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets==7.6.5) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets==7.6.5) (57.4.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets==7.6.5) (0.8.1)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets==7.6.5) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets==7.6.5) (1.0.18)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets==7.6.5) (2.6.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets==7.6.5) (2.6.0)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets==7.6.5) (4.9.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets==7.6.5) (0.2.5)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.35.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.23.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.1.1)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets==7.6.5) (5.3.1)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.6.5) (0.12.1)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.6.5) (5.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.6.5) (2.11.3)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.6.5) (1.8.0)\n",
      "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets==7.6.5) (22.3.0)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.6.5) (0.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.6.5) (2.0.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.6.5) (1.5.0)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.6.5) (0.5.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.6.5) (0.8.4)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.6.5) (4.1.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.6.5) (0.3)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.6.5) (0.7.1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.6.5) (0.5.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.6.5) (21.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install \\\n",
    "    ipywidgets==7.6.5 \\\n",
    "    networkx==2.4 \\\n",
    "    matplotlib==3.2.2 \\\n",
    "    scikit-learn==0.24.0 \\\n",
    "    pandas==1.1.3 \\\n",
    "    numpy==1.19.2 \\\n",
    "    tensorflow==2.4.1 \\\n",
    "    neural-structured-learning==1.3.1 \\\n",
    "    stellargraph==1.2.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLROGCwL61Wc"
   },
   "source": [
    "# Neural Graph Learning and Graph Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKvNCReZ61Wd"
   },
   "source": [
    "In this tutorial, we will be creating a graph regularized version for a topic classification task. The task is to classify paper depending on their content. However in order to do so, we will also use the information encoded in the citation network that relates documents among each other. Of course, we do know that this kind of information is indeed powerful as papers belonging to the same subject tend to reference each other.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8QHRz9a61Wd"
   },
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqpD6TCs61We"
   },
   "source": [
    "For this tutorial we will be using the Cora dataset available in the stellargraph library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "h0_X4_BS61We"
   },
   "outputs": [],
   "source": [
    "from stellargraph import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MpFkxUrV61Wf"
   },
   "outputs": [],
   "source": [
    "dataset = datasets.Cora()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mhY1dk5i61Wg",
    "outputId": "70bf997b-9e9d-4103-a51a-111e031a9b13"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Config option `use_jedi` not recognized by `IPCompleter`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WAzEqIT161Wg"
   },
   "outputs": [],
   "source": [
    "dataset.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RWvso9l-61Wh"
   },
   "outputs": [],
   "source": [
    "label_index = {\n",
    "      'Case_Based': 0,\n",
    "      'Genetic_Algorithms': 1,\n",
    "      'Neural_Networks': 2,\n",
    "      'Probabilistic_Methods': 3,\n",
    "      'Reinforcement_Learning': 4,\n",
    "      'Rule_Learning': 5,\n",
    "      'Theory': 6,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "l6RyScwv61Wh"
   },
   "outputs": [],
   "source": [
    "G, labels = dataset.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBmjy6cF61Wi"
   },
   "source": [
    "We now create the Dataset object where we will both include information of the targeted sample (node) and its neighbors. In the following we will also allow to control the number of labelling instances to be used, in order to reproduce and evaluate the classification performance in a semi-supervised setting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_kFrExKr61Wi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing, feature_extraction, model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nhMrKLt661Wi"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.train import Example, Features, Feature, Int64List, BytesList, FloatList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "D2W3NveN61Wj"
   },
   "outputs": [],
   "source": [
    "GRAPH_PREFIX=\"NL_nbr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "UiQojcFD61Wj"
   },
   "outputs": [],
   "source": [
    "def _int64_feature(*value):\n",
    "    \"\"\"Returns int64 tf.train.Feature from a bool / enum / int / uint.\"\"\"\n",
    "    return Feature(int64_list=Int64List(value=list(value)))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns bytes tf.train.Feature from a string.\"\"\"\n",
    "    return Feature(\n",
    "        bytes_list=BytesList(value=[value.encode('utf-8')])\n",
    "    )\n",
    "\n",
    "def _float_feature(*value):\n",
    "    return Feature(float_list=FloatList(value=list(value)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xFcEHy8t61Wj"
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from typing import List, Tuple\n",
    "import pandas as pd\n",
    "import six\n",
    "\n",
    "def addFeatures(x, y):\n",
    "    res = Features()\n",
    "    res.CopyFrom(x)\n",
    "    res.MergeFrom(y)\n",
    "    return res\n",
    "\n",
    "def neighborFeatures(features: Features, weight: float, prefix: str):\n",
    "    data = {f\"{prefix}_weight\": _float_feature(weight)}\n",
    "    for name, feature in six.iteritems(features.feature):\n",
    "        data[f\"{prefix}_{name}\"] = feature \n",
    "    return Features(feature=data)\n",
    "\n",
    "def neighborsFeatures(neighbors: List[Tuple[Features, float]]):\n",
    "    return reduce(\n",
    "        addFeatures, \n",
    "        [neighborFeatures(sample, weight, f\"{GRAPH_PREFIX}_{ith}\") for ith, (sample, weight) in enumerate(neighbors)],\n",
    "        Features()\n",
    "    )\n",
    "\n",
    "def getNeighbors(idx, adjMatrix, topn=5):\n",
    "    weights = adjMatrix.loc[idx]\n",
    "    return weights[weights>0].sort_values(ascending=False).head(topn).to_dict()\n",
    "    \n",
    "\n",
    "def semisupervisedDataset(G, labels, ratio=0.2, topn=5):\n",
    "    n = int(np.round(len(labels)*ratio))\n",
    "    \n",
    "    labelled, unlabelled = model_selection.train_test_split(\n",
    "        labels, train_size=n, test_size=None, stratify=labels\n",
    "    )\n",
    "    \n",
    "    adjMatrix = pd.DataFrame.sparse.from_spmatrix(G.to_adjacency_matrix(), index=G.nodes(), columns=G.nodes())\n",
    "    \n",
    "    features = pd.DataFrame(G.node_features(), index=G.nodes())\n",
    "    \n",
    "    dataset = {\n",
    "        index: Features(feature = {\n",
    "            #\"id\": _bytes_feature(str(index)), \n",
    "            \"id\": _int64_feature(index),\n",
    "            \"words\": _float_feature(*[float(x) for x in features.loc[index].values]), \n",
    "            \"label\": _int64_feature(label_index[label])\n",
    "        })\n",
    "        for index, label in pd.concat([labelled, unlabelled]).items()\n",
    "    }\n",
    "    \n",
    "    trainingSet = [\n",
    "        Example(features=addFeatures(\n",
    "            dataset[exampleId], \n",
    "            neighborsFeatures(\n",
    "                [(dataset[nodeId], weight) for nodeId, weight in getNeighbors(exampleId, adjMatrix, topn).items()]\n",
    "            )\n",
    "        ))\n",
    "        for exampleId in labelled.index\n",
    "    ]\n",
    "    \n",
    "    testSet = [Example(features=dataset[exampleId]) for exampleId in unlabelled.index]\n",
    "\n",
    "    serializer = lambda _list: [e.SerializeToString() for e in _list]\n",
    "    \n",
    "    return serializer(trainingSet), serializer(testSet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hfi5kD2I61Wk"
   },
   "source": [
    "We split the dataset into a training set and a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1Sp7SM7061Wl"
   },
   "outputs": [],
   "source": [
    "trainingSet, testSet = semisupervisedDataset(G, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2BDc6UAM61Wl"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "8sRGj8Jc61Wm"
   },
   "outputs": [],
   "source": [
    "from tensorflow.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5Kr1yaYg61Wm"
   },
   "outputs": [],
   "source": [
    "vocabularySize = 1433"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "D9JrUNHC61Wm"
   },
   "outputs": [],
   "source": [
    "neighbors=2\n",
    "defaultWord = tf.constant(0, dtype=tf.float32, shape=[vocabularySize])\n",
    "\n",
    "def parseExample(example, training=True):\n",
    "    schema = {\n",
    "        'words': tf.io.FixedLenFeature([vocabularySize], tf.float32, default_value=defaultWord),\n",
    "        'label': tf.io.FixedLenFeature((), tf.int64, default_value=-1)\n",
    "    }\n",
    "    \n",
    "    if training is True:\n",
    "        for i in range(neighbors):\n",
    "            name = f\"{GRAPH_PREFIX}_{i}\"\n",
    "            schema[f\"{name}_weight\"] = tf.io.FixedLenFeature([1], tf.float32, default_value=[0.0])\n",
    "            schema[f\"{name}_words\"] = tf.io.FixedLenFeature([vocabularySize], tf.float32, default_value=defaultWord)\n",
    "    \n",
    "    features = tf.io.parse_single_example(example, schema)\n",
    "    \n",
    "    label = features.pop(\"label\")\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "8X_v_0Ak61Wo"
   },
   "outputs": [],
   "source": [
    "def sampleGenerator(dataset):\n",
    "    def wrapper():\n",
    "        for example in dataset:\n",
    "            yield example\n",
    "    return wrapper\n",
    "            \n",
    "myTrain = Dataset \\\n",
    "    .from_generator(sampleGenerator(trainingSet), output_types=tf.string, output_shapes=()) \\\n",
    "    .map(lambda x: parseExample(x, True))\n",
    "\n",
    "myTest = Dataset \\\n",
    "    .from_generator(sampleGenerator(testSet), output_types=tf.string, output_shapes=()) \\\n",
    "    .map(lambda x: parseExample(x, False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ysWn-4Xv61Wo",
    "outputId": "7a7ea2db-0488-49d8-9bff-8469fb26ceff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NL_nbr_0_weight': <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
      "array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.]], dtype=float32)>, 'NL_nbr_0_words': <tf.Tensor: shape=(10, 1433), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 1.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, 'NL_nbr_1_weight': <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
      "array([[1.],\n",
      "       [0.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [0.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.]], dtype=float32)>, 'NL_nbr_1_words': <tf.Tensor: shape=(10, 1433), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)>, 'words': <tf.Tensor: shape=(10, 1433), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 1.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>}\n",
      "tf.Tensor([2 3 3 6 3 3 2 1 6 3], shape=(10,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for features, labels in myTrain.batch(10).take(1):\n",
    "    print(features)\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "baANJ_E561Wp",
    "outputId": "a3f82319-03fd-4ccd-fbf9-eef8b9ce7f05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words': <tf.Tensor: shape=(10, 1433), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>}\n",
      "tf.Tensor([6 1 2 2 0 0 3 3 0 6], shape=(10,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for features, labels in myTest.batch(10).take(1):\n",
    "    print(features)\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTbDcFO761Wp"
   },
   "source": [
    "### Creating the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMmJTCbf61Wq"
   },
   "source": [
    "We now create the model that we will use to classify the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "FLuu9ZMR61Wq"
   },
   "outputs": [],
   "source": [
    "layers = [50, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "EjN95Y-C61Wq"
   },
   "outputs": [],
   "source": [
    "\"\"\"Creates a functional API-based multi-layer perceptron model.\"\"\"\n",
    "def create_model(num_units):\n",
    "    inputs = tf.keras.Input(\n",
    "          shape=(vocabularySize,), dtype='float32', name='words'\n",
    "    )\n",
    "\n",
    "    # outputs = tf.keras.layers.Dense(len(label_index), activation='softmax')(inputs)\n",
    "\n",
    "    cur_layer =  inputs\n",
    "\n",
    "    for num_units in layers:\n",
    "        cur_layer = tf.keras.layers.Dense(num_units, activation='relu')(cur_layer)\n",
    "        cur_layer = tf.keras.layers.Dropout(0.8)(cur_layer)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(len(label_index), activation='softmax')(cur_layer)\n",
    "\n",
    "    return tf.keras.Model(inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "q0ErB5xi61Wq"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BndJom9h61Wq"
   },
   "source": [
    "#### Vanilla Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-6raPRN61Wq"
   },
   "source": [
    "We first train a simple, vanilla version that does not use the citation network information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "dnpm_1cF61Wr"
   },
   "outputs": [],
   "source": [
    "model = create_model([50, 50])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eVZ3vsyD61Wr",
    "outputId": "200030ff-a292-4f54-e084-4f0e30635259"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "words (InputLayer)           [(None, 1433)]            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                71700     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 357       \n",
      "=================================================================\n",
      "Total params: 74,607\n",
      "Trainable params: 74,607\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bssZTxm61Wr",
    "outputId": "bdf980e4-1afb-4f61-876e-7fa4c2318f7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['NL_nbr_0_weight', 'NL_nbr_0_words', 'NL_nbr_1_weight', 'NL_nbr_1_words'] which did not match any model input. They will be ignored by the model.\n",
      "  [n for n in tensors.keys() if n not in ref_input_names])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 257ms/step - loss: 2.0266 - accuracy: 0.1286 - val_loss: 1.9498 - val_accuracy: 0.1191\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 2.0461 - accuracy: 0.1541 - val_loss: 1.9392 - val_accuracy: 0.1745\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 2.0161 - accuracy: 0.1524 - val_loss: 1.9306 - val_accuracy: 0.2350\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.9935 - accuracy: 0.1825 - val_loss: 1.9235 - val_accuracy: 0.2756\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.9533 - accuracy: 0.1813 - val_loss: 1.9176 - val_accuracy: 0.2959\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 1.9619 - accuracy: 0.2012 - val_loss: 1.9126 - val_accuracy: 0.3024\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.9285 - accuracy: 0.2066 - val_loss: 1.9077 - val_accuracy: 0.3121\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 1.9635 - accuracy: 0.1925 - val_loss: 1.9033 - val_accuracy: 0.3112\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.9222 - accuracy: 0.2157 - val_loss: 1.8994 - val_accuracy: 0.3121\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 1.9247 - accuracy: 0.2194 - val_loss: 1.8952 - val_accuracy: 0.3121\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 1.8886 - accuracy: 0.2521 - val_loss: 1.8902 - val_accuracy: 0.3093\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.8816 - accuracy: 0.2498 - val_loss: 1.8847 - val_accuracy: 0.3098\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.8710 - accuracy: 0.2696 - val_loss: 1.8789 - val_accuracy: 0.3102\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.8731 - accuracy: 0.2714 - val_loss: 1.8730 - val_accuracy: 0.3079\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.8451 - accuracy: 0.2669 - val_loss: 1.8663 - val_accuracy: 0.3089\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.8701 - accuracy: 0.2555 - val_loss: 1.8594 - val_accuracy: 0.3070\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 1.8672 - accuracy: 0.2550 - val_loss: 1.8530 - val_accuracy: 0.3075\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 1.8505 - accuracy: 0.2720 - val_loss: 1.8472 - val_accuracy: 0.3075\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 1.8339 - accuracy: 0.2688 - val_loss: 1.8407 - val_accuracy: 0.3066\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.8280 - accuracy: 0.2756 - val_loss: 1.8344 - val_accuracy: 0.3052\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 1.8341 - accuracy: 0.2865 - val_loss: 1.8288 - val_accuracy: 0.3047\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.8041 - accuracy: 0.2767 - val_loss: 1.8225 - val_accuracy: 0.3042\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 1.8214 - accuracy: 0.2646 - val_loss: 1.8173 - val_accuracy: 0.3056\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.8157 - accuracy: 0.2691 - val_loss: 1.8116 - val_accuracy: 0.3056\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.8177 - accuracy: 0.2966 - val_loss: 1.8057 - val_accuracy: 0.3070\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.7994 - accuracy: 0.3098 - val_loss: 1.7993 - val_accuracy: 0.3075\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.7824 - accuracy: 0.2816 - val_loss: 1.7927 - val_accuracy: 0.3075\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 1.7741 - accuracy: 0.2907 - val_loss: 1.7858 - val_accuracy: 0.3084\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 1.7707 - accuracy: 0.3139 - val_loss: 1.7794 - val_accuracy: 0.3102\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 1.7726 - accuracy: 0.2968 - val_loss: 1.7727 - val_accuracy: 0.3112\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.7646 - accuracy: 0.3101 - val_loss: 1.7665 - val_accuracy: 0.3126\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 1.7564 - accuracy: 0.3026 - val_loss: 1.7604 - val_accuracy: 0.3144\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 1.7322 - accuracy: 0.3108 - val_loss: 1.7528 - val_accuracy: 0.3149\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 1.7585 - accuracy: 0.3255 - val_loss: 1.7455 - val_accuracy: 0.3158\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 1.7544 - accuracy: 0.3059 - val_loss: 1.7384 - val_accuracy: 0.3186\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 1.6735 - accuracy: 0.3349 - val_loss: 1.7304 - val_accuracy: 0.3246\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 1.7332 - accuracy: 0.3104 - val_loss: 1.7219 - val_accuracy: 0.3259\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.7314 - accuracy: 0.3256 - val_loss: 1.7144 - val_accuracy: 0.3310\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 1.6753 - accuracy: 0.3283 - val_loss: 1.7063 - val_accuracy: 0.3352\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 1.7055 - accuracy: 0.3465 - val_loss: 1.7001 - val_accuracy: 0.3426\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.6581 - accuracy: 0.3214 - val_loss: 1.6936 - val_accuracy: 0.3513\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.6802 - accuracy: 0.3414 - val_loss: 1.6877 - val_accuracy: 0.3596\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.6553 - accuracy: 0.3295 - val_loss: 1.6806 - val_accuracy: 0.3666\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 1.6529 - accuracy: 0.3492 - val_loss: 1.6728 - val_accuracy: 0.3730\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 1.6513 - accuracy: 0.3593 - val_loss: 1.6639 - val_accuracy: 0.3795\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.6043 - accuracy: 0.3922 - val_loss: 1.6537 - val_accuracy: 0.3887\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 1.5749 - accuracy: 0.3784 - val_loss: 1.6429 - val_accuracy: 0.3934\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 1.5827 - accuracy: 0.3656 - val_loss: 1.6318 - val_accuracy: 0.3984\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.6118 - accuracy: 0.3715 - val_loss: 1.6214 - val_accuracy: 0.4090\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.5886 - accuracy: 0.3495 - val_loss: 1.6118 - val_accuracy: 0.4151\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 1.5935 - accuracy: 0.3626 - val_loss: 1.6035 - val_accuracy: 0.4187\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.6048 - accuracy: 0.3536 - val_loss: 1.5959 - val_accuracy: 0.4257\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 1.5038 - accuracy: 0.4149 - val_loss: 1.5871 - val_accuracy: 0.4363\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 1.5429 - accuracy: 0.3948 - val_loss: 1.5778 - val_accuracy: 0.4437\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 1.5510 - accuracy: 0.3627 - val_loss: 1.5689 - val_accuracy: 0.4511\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.5462 - accuracy: 0.4012 - val_loss: 1.5595 - val_accuracy: 0.4538\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.5217 - accuracy: 0.3972 - val_loss: 1.5505 - val_accuracy: 0.4575\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.5316 - accuracy: 0.3914 - val_loss: 1.5423 - val_accuracy: 0.4654\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.5098 - accuracy: 0.3747 - val_loss: 1.5340 - val_accuracy: 0.4751\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.4500 - accuracy: 0.3943 - val_loss: 1.5255 - val_accuracy: 0.4857\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.4616 - accuracy: 0.4225 - val_loss: 1.5158 - val_accuracy: 0.4898\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 1.4514 - accuracy: 0.3922 - val_loss: 1.5074 - val_accuracy: 0.4945\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 1.4490 - accuracy: 0.4431 - val_loss: 1.4988 - val_accuracy: 0.4991\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.4645 - accuracy: 0.4043 - val_loss: 1.4899 - val_accuracy: 0.5037\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.4674 - accuracy: 0.4137 - val_loss: 1.4832 - val_accuracy: 0.5083\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.4002 - accuracy: 0.4499 - val_loss: 1.4752 - val_accuracy: 0.5088\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 1.3869 - accuracy: 0.4548 - val_loss: 1.4651 - val_accuracy: 0.5097\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 1.4507 - accuracy: 0.4076 - val_loss: 1.4556 - val_accuracy: 0.5111\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.4000 - accuracy: 0.4226 - val_loss: 1.4470 - val_accuracy: 0.5148\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 1.3828 - accuracy: 0.4575 - val_loss: 1.4383 - val_accuracy: 0.5166\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 1.3668 - accuracy: 0.4523 - val_loss: 1.4305 - val_accuracy: 0.5189\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 1.4063 - accuracy: 0.4253 - val_loss: 1.4238 - val_accuracy: 0.5212\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.3638 - accuracy: 0.4387 - val_loss: 1.4179 - val_accuracy: 0.5231\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.3701 - accuracy: 0.4340 - val_loss: 1.4119 - val_accuracy: 0.5222\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 1.3397 - accuracy: 0.4790 - val_loss: 1.4051 - val_accuracy: 0.5240\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 1.2946 - accuracy: 0.4758 - val_loss: 1.3991 - val_accuracy: 0.5268\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 1.2933 - accuracy: 0.4882 - val_loss: 1.3926 - val_accuracy: 0.5319\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.3695 - accuracy: 0.4347 - val_loss: 1.3872 - val_accuracy: 0.5337\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 1.3194 - accuracy: 0.4567 - val_loss: 1.3804 - val_accuracy: 0.5374\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.3249 - accuracy: 0.4631 - val_loss: 1.3729 - val_accuracy: 0.5416\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.3393 - accuracy: 0.4723 - val_loss: 1.3651 - val_accuracy: 0.5457\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 1.2823 - accuracy: 0.4584 - val_loss: 1.3580 - val_accuracy: 0.5503\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 1.2215 - accuracy: 0.5171 - val_loss: 1.3521 - val_accuracy: 0.5536\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.2714 - accuracy: 0.4876 - val_loss: 1.3456 - val_accuracy: 0.5545\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 1.2156 - accuracy: 0.5131 - val_loss: 1.3399 - val_accuracy: 0.5572\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.2357 - accuracy: 0.5073 - val_loss: 1.3335 - val_accuracy: 0.5596\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 1.2317 - accuracy: 0.4920 - val_loss: 1.3268 - val_accuracy: 0.5633\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 1.2349 - accuracy: 0.5036 - val_loss: 1.3203 - val_accuracy: 0.5656\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.2717 - accuracy: 0.4735 - val_loss: 1.3149 - val_accuracy: 0.5665\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 1.2017 - accuracy: 0.5355 - val_loss: 1.3097 - val_accuracy: 0.5720\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 1.2546 - accuracy: 0.4900 - val_loss: 1.3049 - val_accuracy: 0.5725\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 1.1705 - accuracy: 0.5301 - val_loss: 1.3002 - val_accuracy: 0.5725\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.1762 - accuracy: 0.5140 - val_loss: 1.2957 - val_accuracy: 0.5748\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 1.1542 - accuracy: 0.5415 - val_loss: 1.2923 - val_accuracy: 0.5762\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 1.2279 - accuracy: 0.5224 - val_loss: 1.2875 - val_accuracy: 0.5776\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.1823 - accuracy: 0.5266 - val_loss: 1.2828 - val_accuracy: 0.5794\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.1481 - accuracy: 0.5181 - val_loss: 1.2779 - val_accuracy: 0.5794\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 1.1791 - accuracy: 0.5378 - val_loss: 1.2725 - val_accuracy: 0.5840\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.1487 - accuracy: 0.5273 - val_loss: 1.2685 - val_accuracy: 0.5840\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 1.1576 - accuracy: 0.5230 - val_loss: 1.2661 - val_accuracy: 0.5822\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 1.1707 - accuracy: 0.5242 - val_loss: 1.2637 - val_accuracy: 0.5826\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 1.0970 - accuracy: 0.5748 - val_loss: 1.2602 - val_accuracy: 0.5854\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 1.1396 - accuracy: 0.5417 - val_loss: 1.2596 - val_accuracy: 0.5831\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.0874 - accuracy: 0.5807 - val_loss: 1.2579 - val_accuracy: 0.5845\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.1223 - accuracy: 0.5509 - val_loss: 1.2547 - val_accuracy: 0.5863\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 1.1417 - accuracy: 0.5524 - val_loss: 1.2498 - val_accuracy: 0.5891\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.1209 - accuracy: 0.5337 - val_loss: 1.2448 - val_accuracy: 0.5877\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 1.0672 - accuracy: 0.6048 - val_loss: 1.2410 - val_accuracy: 0.5868\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 1.1083 - accuracy: 0.5713 - val_loss: 1.2382 - val_accuracy: 0.5849\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 1.0919 - accuracy: 0.5570 - val_loss: 1.2369 - val_accuracy: 0.5854\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.0876 - accuracy: 0.5687 - val_loss: 1.2351 - val_accuracy: 0.5849\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 1.0868 - accuracy: 0.5699 - val_loss: 1.2333 - val_accuracy: 0.5849\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 1.0939 - accuracy: 0.5620 - val_loss: 1.2332 - val_accuracy: 0.5863\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.0948 - accuracy: 0.5467 - val_loss: 1.2319 - val_accuracy: 0.5868\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.0828 - accuracy: 0.5719 - val_loss: 1.2295 - val_accuracy: 0.5900\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.0981 - accuracy: 0.5558 - val_loss: 1.2275 - val_accuracy: 0.5886\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 1.0089 - accuracy: 0.6155 - val_loss: 1.2248 - val_accuracy: 0.5905\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 1.0376 - accuracy: 0.5721 - val_loss: 1.2240 - val_accuracy: 0.5896\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.0707 - accuracy: 0.5715 - val_loss: 1.2260 - val_accuracy: 0.5914\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.0404 - accuracy: 0.5846 - val_loss: 1.2273 - val_accuracy: 0.5910\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.0074 - accuracy: 0.6120 - val_loss: 1.2274 - val_accuracy: 0.5900\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.9706 - accuracy: 0.6256 - val_loss: 1.2268 - val_accuracy: 0.5882\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.0676 - accuracy: 0.5647 - val_loss: 1.2258 - val_accuracy: 0.5896\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.9954 - accuracy: 0.5934 - val_loss: 1.2229 - val_accuracy: 0.5891\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.9627 - accuracy: 0.5961 - val_loss: 1.2213 - val_accuracy: 0.5900\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 1.0586 - accuracy: 0.5734 - val_loss: 1.2209 - val_accuracy: 0.5905\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 1.0332 - accuracy: 0.5841 - val_loss: 1.2211 - val_accuracy: 0.5905\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.0295 - accuracy: 0.5694 - val_loss: 1.2218 - val_accuracy: 0.5896\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.0425 - accuracy: 0.5864 - val_loss: 1.2235 - val_accuracy: 0.5891\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.0108 - accuracy: 0.5952 - val_loss: 1.2256 - val_accuracy: 0.5910\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.9728 - accuracy: 0.5999 - val_loss: 1.2268 - val_accuracy: 0.5905\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.9870 - accuracy: 0.5782 - val_loss: 1.2256 - val_accuracy: 0.5914\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.9443 - accuracy: 0.6112 - val_loss: 1.2250 - val_accuracy: 0.5914\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.9876 - accuracy: 0.6193 - val_loss: 1.2249 - val_accuracy: 0.5928\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.9698 - accuracy: 0.6103 - val_loss: 1.2271 - val_accuracy: 0.5933\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.9395 - accuracy: 0.6332 - val_loss: 1.2264 - val_accuracy: 0.5946\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.0000 - accuracy: 0.6001 - val_loss: 1.2258 - val_accuracy: 0.5951\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.9953 - accuracy: 0.6147 - val_loss: 1.2254 - val_accuracy: 0.5956\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.9582 - accuracy: 0.6260 - val_loss: 1.2277 - val_accuracy: 0.5956\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.9698 - accuracy: 0.6114 - val_loss: 1.2273 - val_accuracy: 0.5937\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.9661 - accuracy: 0.6273 - val_loss: 1.2291 - val_accuracy: 0.5937\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.9813 - accuracy: 0.5709 - val_loss: 1.2324 - val_accuracy: 0.5933\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.9061 - accuracy: 0.6343 - val_loss: 1.2356 - val_accuracy: 0.5923\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.9895 - accuracy: 0.5888 - val_loss: 1.2373 - val_accuracy: 0.5919\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.8949 - accuracy: 0.6479 - val_loss: 1.2370 - val_accuracy: 0.5923\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.9272 - accuracy: 0.6376 - val_loss: 1.2398 - val_accuracy: 0.5928\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.9804 - accuracy: 0.5960 - val_loss: 1.2395 - val_accuracy: 0.5942\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.8923 - accuracy: 0.6562 - val_loss: 1.2396 - val_accuracy: 0.5951\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.9329 - accuracy: 0.6234 - val_loss: 1.2399 - val_accuracy: 0.5979\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.9409 - accuracy: 0.6184 - val_loss: 1.2391 - val_accuracy: 0.5979\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.9449 - accuracy: 0.6216 - val_loss: 1.2413 - val_accuracy: 0.5993\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.8817 - accuracy: 0.6765 - val_loss: 1.2430 - val_accuracy: 0.5983\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.9184 - accuracy: 0.6497 - val_loss: 1.2467 - val_accuracy: 0.5983\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.8357 - accuracy: 0.6600 - val_loss: 1.2504 - val_accuracy: 0.5979\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.9118 - accuracy: 0.6318 - val_loss: 1.2518 - val_accuracy: 0.5979\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.8692 - accuracy: 0.6384 - val_loss: 1.2507 - val_accuracy: 0.5993\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.9195 - accuracy: 0.6233 - val_loss: 1.2533 - val_accuracy: 0.5993\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.9038 - accuracy: 0.6382 - val_loss: 1.2561 - val_accuracy: 0.5997\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.8329 - accuracy: 0.6741 - val_loss: 1.2621 - val_accuracy: 0.5988\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.8470 - accuracy: 0.6395 - val_loss: 1.2634 - val_accuracy: 0.5997\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.8794 - accuracy: 0.6534 - val_loss: 1.2618 - val_accuracy: 0.6020\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.8416 - accuracy: 0.6590 - val_loss: 1.2612 - val_accuracy: 0.6020\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.9164 - accuracy: 0.6475 - val_loss: 1.2611 - val_accuracy: 0.6030\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.8800 - accuracy: 0.6534 - val_loss: 1.2618 - val_accuracy: 0.6034\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.8843 - accuracy: 0.6746 - val_loss: 1.2648 - val_accuracy: 0.6039\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.8332 - accuracy: 0.6742 - val_loss: 1.2676 - val_accuracy: 0.6034\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.9102 - accuracy: 0.6222 - val_loss: 1.2724 - val_accuracy: 0.6025\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.8660 - accuracy: 0.6884 - val_loss: 1.2805 - val_accuracy: 0.6030\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.8809 - accuracy: 0.6431 - val_loss: 1.2862 - val_accuracy: 0.6030\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.8868 - accuracy: 0.6605 - val_loss: 1.2836 - val_accuracy: 0.6034\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.8522 - accuracy: 0.6718 - val_loss: 1.2774 - val_accuracy: 0.6043\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.8957 - accuracy: 0.6428 - val_loss: 1.2724 - val_accuracy: 0.6053\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.8455 - accuracy: 0.6760 - val_loss: 1.2728 - val_accuracy: 0.6057\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.8793 - accuracy: 0.6388 - val_loss: 1.2737 - val_accuracy: 0.6062\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.8254 - accuracy: 0.7014 - val_loss: 1.2791 - val_accuracy: 0.6057\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.8087 - accuracy: 0.6695 - val_loss: 1.2848 - val_accuracy: 0.6062\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.7726 - accuracy: 0.6720 - val_loss: 1.2903 - val_accuracy: 0.6062\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.8548 - accuracy: 0.6585 - val_loss: 1.2949 - val_accuracy: 0.6048\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.8391 - accuracy: 0.6409 - val_loss: 1.2975 - val_accuracy: 0.6057\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.8611 - accuracy: 0.6452 - val_loss: 1.2991 - val_accuracy: 0.6048\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.8151 - accuracy: 0.6674 - val_loss: 1.2999 - val_accuracy: 0.6062\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.8562 - accuracy: 0.6394 - val_loss: 1.2980 - val_accuracy: 0.6053\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.8166 - accuracy: 0.6444 - val_loss: 1.2940 - val_accuracy: 0.6053\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.8501 - accuracy: 0.6456 - val_loss: 1.2912 - val_accuracy: 0.6057\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.8094 - accuracy: 0.6818 - val_loss: 1.2919 - val_accuracy: 0.6057\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.7997 - accuracy: 0.6728 - val_loss: 1.2952 - val_accuracy: 0.6057\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.8497 - accuracy: 0.6277 - val_loss: 1.2979 - val_accuracy: 0.6057\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.8608 - accuracy: 0.6420 - val_loss: 1.3040 - val_accuracy: 0.6048\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.8046 - accuracy: 0.6613 - val_loss: 1.3098 - val_accuracy: 0.6048\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.7797 - accuracy: 0.7036 - val_loss: 1.3129 - val_accuracy: 0.6034\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.8036 - accuracy: 0.6836 - val_loss: 1.3132 - val_accuracy: 0.6039\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.7910 - accuracy: 0.6903 - val_loss: 1.3145 - val_accuracy: 0.6057\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.7487 - accuracy: 0.7027 - val_loss: 1.3202 - val_accuracy: 0.6062\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.8647 - accuracy: 0.6395 - val_loss: 1.3272 - val_accuracy: 0.6062\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.7585 - accuracy: 0.6766 - val_loss: 1.3314 - val_accuracy: 0.6066\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.7920 - accuracy: 0.6750 - val_loss: 1.3355 - val_accuracy: 0.6053\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.8007 - accuracy: 0.6982 - val_loss: 1.3418 - val_accuracy: 0.6071\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.7989 - accuracy: 0.6718 - val_loss: 1.3460 - val_accuracy: 0.6080\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.8194 - accuracy: 0.6699 - val_loss: 1.3449 - val_accuracy: 0.6071\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.8161 - accuracy: 0.6890 - val_loss: 1.3464 - val_accuracy: 0.6062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f20ed4747d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(myTrain.batch(128), epochs=200, verbose=1, validation_data=myTest.batch(128),\n",
    "          callbacks=[TensorBoard(log_dir='/tmp/noRegularization')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQv-y0M261Wr"
   },
   "source": [
    "#### Graph Regularized Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqKViSTv61Wr"
   },
   "source": [
    "We now create the graph-regularized version that uses the citation network information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "MT5W6McW61Ws"
   },
   "outputs": [],
   "source": [
    "base_model = create_model([50, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "B7rtiS-261Ws"
   },
   "outputs": [],
   "source": [
    "import neural_structured_learning as nsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "lNbzYn7K61Ws"
   },
   "outputs": [],
   "source": [
    "graph_reg_config = nsl.configs.make_graph_reg_config(\n",
    "    max_neighbors=2,\n",
    "    multiplier=0.1,\n",
    "    distance_type=nsl.configs.DistanceType.L2,\n",
    "    sum_over_axis=-1)\n",
    "graph_reg_model = nsl.keras.GraphRegularization(base_model,\n",
    "                                                graph_reg_config)\n",
    "graph_reg_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "#graph_reg_model.fit(train_dataset, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RCNQYW1E61Ws",
    "outputId": "382ec7db-fde5-4f99-be3a-8de78f49bf5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Reshape:0\", shape=(None, 7), dtype=float32), dense_shape=Tensor(\"gradient_tape/GraphRegularization/graph_loss/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 201ms/step - loss: 2.0773 - accuracy: 0.1336 - scaled_graph_loss: 0.0062 - val_loss: 1.9514 - val_accuracy: 0.1219\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 2.0178 - accuracy: 0.1899 - scaled_graph_loss: 0.0056 - val_loss: 1.9369 - val_accuracy: 0.1994\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.9884 - accuracy: 0.1983 - scaled_graph_loss: 0.0045 - val_loss: 1.9263 - val_accuracy: 0.2608\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 1.9576 - accuracy: 0.1527 - scaled_graph_loss: 0.0038 - val_loss: 1.9179 - val_accuracy: 0.2982\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.9633 - accuracy: 0.1822 - scaled_graph_loss: 0.0034 - val_loss: 1.9108 - val_accuracy: 0.3139\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.9133 - accuracy: 0.2266 - scaled_graph_loss: 0.0030 - val_loss: 1.9044 - val_accuracy: 0.3126\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.9338 - accuracy: 0.2121 - scaled_graph_loss: 0.0031 - val_loss: 1.8982 - val_accuracy: 0.3158\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 1.9279 - accuracy: 0.1950 - scaled_graph_loss: 0.0029 - val_loss: 1.8923 - val_accuracy: 0.3116\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.9157 - accuracy: 0.2497 - scaled_graph_loss: 0.0027 - val_loss: 1.8865 - val_accuracy: 0.3079\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 1.9054 - accuracy: 0.2265 - scaled_graph_loss: 0.0027 - val_loss: 1.8807 - val_accuracy: 0.3075\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.8783 - accuracy: 0.2522 - scaled_graph_loss: 0.0029 - val_loss: 1.8748 - val_accuracy: 0.3047\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 1.8536 - accuracy: 0.2637 - scaled_graph_loss: 0.0030 - val_loss: 1.8686 - val_accuracy: 0.3042\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 1.8727 - accuracy: 0.2506 - scaled_graph_loss: 0.0031 - val_loss: 1.8632 - val_accuracy: 0.3033\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 1.8549 - accuracy: 0.2588 - scaled_graph_loss: 0.0032 - val_loss: 1.8583 - val_accuracy: 0.3038\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 1.8634 - accuracy: 0.2510 - scaled_graph_loss: 0.0033 - val_loss: 1.8534 - val_accuracy: 0.3038\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.8208 - accuracy: 0.2852 - scaled_graph_loss: 0.0031 - val_loss: 1.8481 - val_accuracy: 0.3038\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 1.8065 - accuracy: 0.2815 - scaled_graph_loss: 0.0033 - val_loss: 1.8419 - val_accuracy: 0.3038\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.8097 - accuracy: 0.2896 - scaled_graph_loss: 0.0035 - val_loss: 1.8348 - val_accuracy: 0.3038\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 1.8192 - accuracy: 0.2803 - scaled_graph_loss: 0.0036 - val_loss: 1.8279 - val_accuracy: 0.3033\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.8012 - accuracy: 0.2774 - scaled_graph_loss: 0.0039 - val_loss: 1.8211 - val_accuracy: 0.3029\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 1.8189 - accuracy: 0.2580 - scaled_graph_loss: 0.0039 - val_loss: 1.8142 - val_accuracy: 0.3029\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.7589 - accuracy: 0.2831 - scaled_graph_loss: 0.0047 - val_loss: 1.8074 - val_accuracy: 0.3024\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.8056 - accuracy: 0.2746 - scaled_graph_loss: 0.0054 - val_loss: 1.8009 - val_accuracy: 0.3024\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.7719 - accuracy: 0.2820 - scaled_graph_loss: 0.0047 - val_loss: 1.7952 - val_accuracy: 0.3024\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 1.7635 - accuracy: 0.2795 - scaled_graph_loss: 0.0052 - val_loss: 1.7900 - val_accuracy: 0.3024\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.7830 - accuracy: 0.2944 - scaled_graph_loss: 0.0048 - val_loss: 1.7847 - val_accuracy: 0.3033\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.7571 - accuracy: 0.2992 - scaled_graph_loss: 0.0050 - val_loss: 1.7787 - val_accuracy: 0.3033\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 1.7524 - accuracy: 0.2927 - scaled_graph_loss: 0.0057 - val_loss: 1.7726 - val_accuracy: 0.3033\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.7609 - accuracy: 0.2901 - scaled_graph_loss: 0.0053 - val_loss: 1.7659 - val_accuracy: 0.3033\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 1.7210 - accuracy: 0.3154 - scaled_graph_loss: 0.0059 - val_loss: 1.7583 - val_accuracy: 0.3033\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.7501 - accuracy: 0.2952 - scaled_graph_loss: 0.0062 - val_loss: 1.7502 - val_accuracy: 0.3033\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.7286 - accuracy: 0.3106 - scaled_graph_loss: 0.0062 - val_loss: 1.7423 - val_accuracy: 0.3042\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 1.7569 - accuracy: 0.2868 - scaled_graph_loss: 0.0061 - val_loss: 1.7354 - val_accuracy: 0.3042\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.6844 - accuracy: 0.3156 - scaled_graph_loss: 0.0068 - val_loss: 1.7278 - val_accuracy: 0.3042\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.6893 - accuracy: 0.3212 - scaled_graph_loss: 0.0071 - val_loss: 1.7213 - val_accuracy: 0.3047\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 1.7047 - accuracy: 0.3157 - scaled_graph_loss: 0.0077 - val_loss: 1.7160 - val_accuracy: 0.3056\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 1.6684 - accuracy: 0.2966 - scaled_graph_loss: 0.0078 - val_loss: 1.7090 - val_accuracy: 0.3066\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 1.6805 - accuracy: 0.3135 - scaled_graph_loss: 0.0068 - val_loss: 1.7019 - val_accuracy: 0.3070\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 1.6534 - accuracy: 0.3237 - scaled_graph_loss: 0.0076 - val_loss: 1.6957 - val_accuracy: 0.3102\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.6568 - accuracy: 0.3375 - scaled_graph_loss: 0.0075 - val_loss: 1.6887 - val_accuracy: 0.3107\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.6356 - accuracy: 0.3285 - scaled_graph_loss: 0.0090 - val_loss: 1.6828 - val_accuracy: 0.3116\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 1.6164 - accuracy: 0.3393 - scaled_graph_loss: 0.0086 - val_loss: 1.6764 - val_accuracy: 0.3130\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 1.5858 - accuracy: 0.3487 - scaled_graph_loss: 0.0103 - val_loss: 1.6687 - val_accuracy: 0.3149\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 1.6138 - accuracy: 0.3325 - scaled_graph_loss: 0.0097 - val_loss: 1.6611 - val_accuracy: 0.3195\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 1.5816 - accuracy: 0.3480 - scaled_graph_loss: 0.0093 - val_loss: 1.6533 - val_accuracy: 0.3250\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 1.6074 - accuracy: 0.3191 - scaled_graph_loss: 0.0098 - val_loss: 1.6458 - val_accuracy: 0.3306\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 1.5917 - accuracy: 0.3470 - scaled_graph_loss: 0.0104 - val_loss: 1.6399 - val_accuracy: 0.3403\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 1.5939 - accuracy: 0.3211 - scaled_graph_loss: 0.0107 - val_loss: 1.6339 - val_accuracy: 0.3490\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 1.5840 - accuracy: 0.3435 - scaled_graph_loss: 0.0112 - val_loss: 1.6291 - val_accuracy: 0.3620\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.5624 - accuracy: 0.3574 - scaled_graph_loss: 0.0114 - val_loss: 1.6236 - val_accuracy: 0.3753\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 1.5484 - accuracy: 0.3541 - scaled_graph_loss: 0.0111 - val_loss: 1.6164 - val_accuracy: 0.3795\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.5366 - accuracy: 0.3501 - scaled_graph_loss: 0.0111 - val_loss: 1.6078 - val_accuracy: 0.3869\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 1.5295 - accuracy: 0.3578 - scaled_graph_loss: 0.0115 - val_loss: 1.5990 - val_accuracy: 0.3966\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 1.5261 - accuracy: 0.3399 - scaled_graph_loss: 0.0125 - val_loss: 1.5900 - val_accuracy: 0.4026\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 1.5486 - accuracy: 0.3717 - scaled_graph_loss: 0.0111 - val_loss: 1.5814 - val_accuracy: 0.4100\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.5202 - accuracy: 0.3858 - scaled_graph_loss: 0.0115 - val_loss: 1.5736 - val_accuracy: 0.4183\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 1.5112 - accuracy: 0.3600 - scaled_graph_loss: 0.0138 - val_loss: 1.5662 - val_accuracy: 0.4215\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.4757 - accuracy: 0.3904 - scaled_graph_loss: 0.0146 - val_loss: 1.5590 - val_accuracy: 0.4289\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.4757 - accuracy: 0.3865 - scaled_graph_loss: 0.0130 - val_loss: 1.5515 - val_accuracy: 0.4317\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.5101 - accuracy: 0.3607 - scaled_graph_loss: 0.0119 - val_loss: 1.5435 - val_accuracy: 0.4363\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 1.5150 - accuracy: 0.3323 - scaled_graph_loss: 0.0133 - val_loss: 1.5361 - val_accuracy: 0.4395\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 1.4668 - accuracy: 0.3886 - scaled_graph_loss: 0.0151 - val_loss: 1.5296 - val_accuracy: 0.4460\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.4453 - accuracy: 0.3992 - scaled_graph_loss: 0.0147 - val_loss: 1.5226 - val_accuracy: 0.4548\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 1.4304 - accuracy: 0.3955 - scaled_graph_loss: 0.0141 - val_loss: 1.5150 - val_accuracy: 0.4612\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.4568 - accuracy: 0.3742 - scaled_graph_loss: 0.0133 - val_loss: 1.5079 - val_accuracy: 0.4668\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 1.4483 - accuracy: 0.4279 - scaled_graph_loss: 0.0149 - val_loss: 1.4992 - val_accuracy: 0.4728\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 1.4143 - accuracy: 0.4375 - scaled_graph_loss: 0.0161 - val_loss: 1.4907 - val_accuracy: 0.4801\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.4048 - accuracy: 0.4220 - scaled_graph_loss: 0.0173 - val_loss: 1.4828 - val_accuracy: 0.4843\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.4165 - accuracy: 0.4222 - scaled_graph_loss: 0.0166 - val_loss: 1.4745 - val_accuracy: 0.4880\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.3609 - accuracy: 0.4361 - scaled_graph_loss: 0.0163 - val_loss: 1.4660 - val_accuracy: 0.4912\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 1.3734 - accuracy: 0.4532 - scaled_graph_loss: 0.0172 - val_loss: 1.4578 - val_accuracy: 0.4972\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 1.3663 - accuracy: 0.4598 - scaled_graph_loss: 0.0164 - val_loss: 1.4500 - val_accuracy: 0.5000\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 1.4059 - accuracy: 0.4452 - scaled_graph_loss: 0.0181 - val_loss: 1.4435 - val_accuracy: 0.5065\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 1.3508 - accuracy: 0.4621 - scaled_graph_loss: 0.0182 - val_loss: 1.4373 - val_accuracy: 0.5106\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 1.3313 - accuracy: 0.4697 - scaled_graph_loss: 0.0194 - val_loss: 1.4307 - val_accuracy: 0.5139\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.3662 - accuracy: 0.4311 - scaled_graph_loss: 0.0176 - val_loss: 1.4238 - val_accuracy: 0.5162\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 1.3512 - accuracy: 0.4826 - scaled_graph_loss: 0.0175 - val_loss: 1.4165 - val_accuracy: 0.5180\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 1.3629 - accuracy: 0.4205 - scaled_graph_loss: 0.0195 - val_loss: 1.4114 - val_accuracy: 0.5212\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 1.3215 - accuracy: 0.4824 - scaled_graph_loss: 0.0208 - val_loss: 1.4059 - val_accuracy: 0.5268\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 1.3196 - accuracy: 0.4939 - scaled_graph_loss: 0.0185 - val_loss: 1.3997 - val_accuracy: 0.5286\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.3382 - accuracy: 0.4693 - scaled_graph_loss: 0.0177 - val_loss: 1.3945 - val_accuracy: 0.5295\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 1.3361 - accuracy: 0.4684 - scaled_graph_loss: 0.0202 - val_loss: 1.3886 - val_accuracy: 0.5295\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.2890 - accuracy: 0.5020 - scaled_graph_loss: 0.0191 - val_loss: 1.3824 - val_accuracy: 0.5309\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 1.2852 - accuracy: 0.4544 - scaled_graph_loss: 0.0209 - val_loss: 1.3767 - val_accuracy: 0.5314\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 1.2461 - accuracy: 0.4918 - scaled_graph_loss: 0.0217 - val_loss: 1.3717 - val_accuracy: 0.5351\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.3068 - accuracy: 0.4906 - scaled_graph_loss: 0.0200 - val_loss: 1.3668 - val_accuracy: 0.5369\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.2810 - accuracy: 0.4867 - scaled_graph_loss: 0.0199 - val_loss: 1.3620 - val_accuracy: 0.5392\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.2387 - accuracy: 0.4963 - scaled_graph_loss: 0.0205 - val_loss: 1.3555 - val_accuracy: 0.5416\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 1.2648 - accuracy: 0.5013 - scaled_graph_loss: 0.0209 - val_loss: 1.3499 - val_accuracy: 0.5425\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.2948 - accuracy: 0.4786 - scaled_graph_loss: 0.0212 - val_loss: 1.3452 - val_accuracy: 0.5476\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.2548 - accuracy: 0.5195 - scaled_graph_loss: 0.0222 - val_loss: 1.3412 - val_accuracy: 0.5476\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 1.2559 - accuracy: 0.4868 - scaled_graph_loss: 0.0218 - val_loss: 1.3375 - val_accuracy: 0.5466\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 1.2217 - accuracy: 0.5120 - scaled_graph_loss: 0.0222 - val_loss: 1.3332 - val_accuracy: 0.5476\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 1.2121 - accuracy: 0.5168 - scaled_graph_loss: 0.0211 - val_loss: 1.3282 - val_accuracy: 0.5485\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 1.2167 - accuracy: 0.5195 - scaled_graph_loss: 0.0239 - val_loss: 1.3234 - val_accuracy: 0.5508\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 1.2151 - accuracy: 0.5620 - scaled_graph_loss: 0.0226 - val_loss: 1.3185 - val_accuracy: 0.5494\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 1.2595 - accuracy: 0.5069 - scaled_graph_loss: 0.0215 - val_loss: 1.3140 - val_accuracy: 0.5512\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.1657 - accuracy: 0.5493 - scaled_graph_loss: 0.0242 - val_loss: 1.3097 - val_accuracy: 0.5508\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.1650 - accuracy: 0.5522 - scaled_graph_loss: 0.0227 - val_loss: 1.3043 - val_accuracy: 0.5517\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 1.1896 - accuracy: 0.5431 - scaled_graph_loss: 0.0234 - val_loss: 1.2991 - val_accuracy: 0.5531\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 1.1461 - accuracy: 0.5458 - scaled_graph_loss: 0.0240 - val_loss: 1.2943 - val_accuracy: 0.5545\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 1.2333 - accuracy: 0.5162 - scaled_graph_loss: 0.0236 - val_loss: 1.2905 - val_accuracy: 0.5559\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 1.2013 - accuracy: 0.5349 - scaled_graph_loss: 0.0250 - val_loss: 1.2874 - val_accuracy: 0.5596\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 1.1309 - accuracy: 0.5486 - scaled_graph_loss: 0.0265 - val_loss: 1.2853 - val_accuracy: 0.5623\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.1802 - accuracy: 0.5549 - scaled_graph_loss: 0.0238 - val_loss: 1.2836 - val_accuracy: 0.5628\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 1.1381 - accuracy: 0.5660 - scaled_graph_loss: 0.0244 - val_loss: 1.2808 - val_accuracy: 0.5651\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 1.1539 - accuracy: 0.5651 - scaled_graph_loss: 0.0249 - val_loss: 1.2769 - val_accuracy: 0.5660\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.1769 - accuracy: 0.5356 - scaled_graph_loss: 0.0257 - val_loss: 1.2725 - val_accuracy: 0.5669\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.1591 - accuracy: 0.5363 - scaled_graph_loss: 0.0269 - val_loss: 1.2697 - val_accuracy: 0.5697\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 1.1505 - accuracy: 0.5638 - scaled_graph_loss: 0.0257 - val_loss: 1.2675 - val_accuracy: 0.5720\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 1.1491 - accuracy: 0.5692 - scaled_graph_loss: 0.0235 - val_loss: 1.2662 - val_accuracy: 0.5771\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 1.1795 - accuracy: 0.5447 - scaled_graph_loss: 0.0245 - val_loss: 1.2636 - val_accuracy: 0.5771\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.1037 - accuracy: 0.5719 - scaled_graph_loss: 0.0282 - val_loss: 1.2610 - val_accuracy: 0.5780\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 1.1070 - accuracy: 0.5852 - scaled_graph_loss: 0.0270 - val_loss: 1.2585 - val_accuracy: 0.5794\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.1581 - accuracy: 0.5528 - scaled_graph_loss: 0.0249 - val_loss: 1.2555 - val_accuracy: 0.5822\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 1.0655 - accuracy: 0.6342 - scaled_graph_loss: 0.0255 - val_loss: 1.2538 - val_accuracy: 0.5817\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 1.0993 - accuracy: 0.5678 - scaled_graph_loss: 0.0274 - val_loss: 1.2525 - val_accuracy: 0.5831\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 1.1164 - accuracy: 0.5638 - scaled_graph_loss: 0.0273 - val_loss: 1.2492 - val_accuracy: 0.5868\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 1.0538 - accuracy: 0.5712 - scaled_graph_loss: 0.0271 - val_loss: 1.2451 - val_accuracy: 0.5873\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.0488 - accuracy: 0.6074 - scaled_graph_loss: 0.0271 - val_loss: 1.2419 - val_accuracy: 0.5905\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 1.0684 - accuracy: 0.5859 - scaled_graph_loss: 0.0290 - val_loss: 1.2405 - val_accuracy: 0.5896\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.0511 - accuracy: 0.5825 - scaled_graph_loss: 0.0308 - val_loss: 1.2391 - val_accuracy: 0.5886\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 1.0699 - accuracy: 0.5668 - scaled_graph_loss: 0.0262 - val_loss: 1.2380 - val_accuracy: 0.5891\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 1.0391 - accuracy: 0.5963 - scaled_graph_loss: 0.0269 - val_loss: 1.2359 - val_accuracy: 0.5910\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 1.1342 - accuracy: 0.5638 - scaled_graph_loss: 0.0291 - val_loss: 1.2363 - val_accuracy: 0.5933\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 1.0645 - accuracy: 0.5979 - scaled_graph_loss: 0.0276 - val_loss: 1.2361 - val_accuracy: 0.5923\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.9674 - accuracy: 0.6425 - scaled_graph_loss: 0.0302 - val_loss: 1.2345 - val_accuracy: 0.5937\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.0271 - accuracy: 0.6199 - scaled_graph_loss: 0.0301 - val_loss: 1.2301 - val_accuracy: 0.5956\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.0984 - accuracy: 0.5867 - scaled_graph_loss: 0.0293 - val_loss: 1.2255 - val_accuracy: 0.5993\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.9820 - accuracy: 0.6299 - scaled_graph_loss: 0.0298 - val_loss: 1.2210 - val_accuracy: 0.5979\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 1.0795 - accuracy: 0.5974 - scaled_graph_loss: 0.0303 - val_loss: 1.2190 - val_accuracy: 0.6006\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 1.0037 - accuracy: 0.6046 - scaled_graph_loss: 0.0286 - val_loss: 1.2184 - val_accuracy: 0.6025\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 1.0276 - accuracy: 0.6373 - scaled_graph_loss: 0.0314 - val_loss: 1.2173 - val_accuracy: 0.6025\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 1.0276 - accuracy: 0.6294 - scaled_graph_loss: 0.0309 - val_loss: 1.2164 - val_accuracy: 0.6011\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 1.0094 - accuracy: 0.6225 - scaled_graph_loss: 0.0287 - val_loss: 1.2184 - val_accuracy: 0.6025\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 1.0207 - accuracy: 0.6377 - scaled_graph_loss: 0.0309 - val_loss: 1.2219 - val_accuracy: 0.6034\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.9972 - accuracy: 0.6384 - scaled_graph_loss: 0.0294 - val_loss: 1.2222 - val_accuracy: 0.6030\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 1.0385 - accuracy: 0.6290 - scaled_graph_loss: 0.0306 - val_loss: 1.2214 - val_accuracy: 0.6048\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.0115 - accuracy: 0.6188 - scaled_graph_loss: 0.0303 - val_loss: 1.2196 - val_accuracy: 0.6076\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.0357 - accuracy: 0.6086 - scaled_graph_loss: 0.0308 - val_loss: 1.2185 - val_accuracy: 0.6103\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.0582 - accuracy: 0.5807 - scaled_graph_loss: 0.0289 - val_loss: 1.2215 - val_accuracy: 0.6071\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 1.0212 - accuracy: 0.6372 - scaled_graph_loss: 0.0273 - val_loss: 1.2261 - val_accuracy: 0.6043\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.9418 - accuracy: 0.6653 - scaled_graph_loss: 0.0295 - val_loss: 1.2296 - val_accuracy: 0.6039\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.9666 - accuracy: 0.6354 - scaled_graph_loss: 0.0327 - val_loss: 1.2290 - val_accuracy: 0.6039\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.9229 - accuracy: 0.6500 - scaled_graph_loss: 0.0311 - val_loss: 1.2274 - val_accuracy: 0.6025\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.9715 - accuracy: 0.6579 - scaled_graph_loss: 0.0289 - val_loss: 1.2243 - val_accuracy: 0.6034\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.9197 - accuracy: 0.6614 - scaled_graph_loss: 0.0323 - val_loss: 1.2223 - val_accuracy: 0.6030\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.9902 - accuracy: 0.6099 - scaled_graph_loss: 0.0302 - val_loss: 1.2212 - val_accuracy: 0.6016\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.9835 - accuracy: 0.6322 - scaled_graph_loss: 0.0287 - val_loss: 1.2177 - val_accuracy: 0.6066\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.9417 - accuracy: 0.6596 - scaled_graph_loss: 0.0299 - val_loss: 1.2174 - val_accuracy: 0.6080\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 1.0046 - accuracy: 0.5955 - scaled_graph_loss: 0.0321 - val_loss: 1.2165 - val_accuracy: 0.6094\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.9558 - accuracy: 0.6316 - scaled_graph_loss: 0.0300 - val_loss: 1.2162 - val_accuracy: 0.6090\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 1.0137 - accuracy: 0.6099 - scaled_graph_loss: 0.0320 - val_loss: 1.2172 - val_accuracy: 0.6090\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.9479 - accuracy: 0.6702 - scaled_graph_loss: 0.0308 - val_loss: 1.2176 - val_accuracy: 0.6113\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.9142 - accuracy: 0.6596 - scaled_graph_loss: 0.0322 - val_loss: 1.2181 - val_accuracy: 0.6131\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.9738 - accuracy: 0.6240 - scaled_graph_loss: 0.0319 - val_loss: 1.2194 - val_accuracy: 0.6136\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.9256 - accuracy: 0.6713 - scaled_graph_loss: 0.0308 - val_loss: 1.2241 - val_accuracy: 0.6150\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.9185 - accuracy: 0.7018 - scaled_graph_loss: 0.0294 - val_loss: 1.2263 - val_accuracy: 0.6150\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.9737 - accuracy: 0.6253 - scaled_graph_loss: 0.0312 - val_loss: 1.2275 - val_accuracy: 0.6163\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.9127 - accuracy: 0.6696 - scaled_graph_loss: 0.0310 - val_loss: 1.2282 - val_accuracy: 0.6177\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.9632 - accuracy: 0.6488 - scaled_graph_loss: 0.0294 - val_loss: 1.2312 - val_accuracy: 0.6173\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.9443 - accuracy: 0.6566 - scaled_graph_loss: 0.0315 - val_loss: 1.2321 - val_accuracy: 0.6182\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.9289 - accuracy: 0.6530 - scaled_graph_loss: 0.0331 - val_loss: 1.2363 - val_accuracy: 0.6159\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.9465 - accuracy: 0.6231 - scaled_graph_loss: 0.0344 - val_loss: 1.2435 - val_accuracy: 0.6159\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.9091 - accuracy: 0.6713 - scaled_graph_loss: 0.0328 - val_loss: 1.2468 - val_accuracy: 0.6168\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.8922 - accuracy: 0.6842 - scaled_graph_loss: 0.0314 - val_loss: 1.2465 - val_accuracy: 0.6182\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.9283 - accuracy: 0.6316 - scaled_graph_loss: 0.0327 - val_loss: 1.2455 - val_accuracy: 0.6191\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.8660 - accuracy: 0.6920 - scaled_graph_loss: 0.0308 - val_loss: 1.2473 - val_accuracy: 0.6205\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.9337 - accuracy: 0.6504 - scaled_graph_loss: 0.0325 - val_loss: 1.2461 - val_accuracy: 0.6214\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.9102 - accuracy: 0.6584 - scaled_graph_loss: 0.0334 - val_loss: 1.2447 - val_accuracy: 0.6210\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.8705 - accuracy: 0.7023 - scaled_graph_loss: 0.0307 - val_loss: 1.2446 - val_accuracy: 0.6228\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.9009 - accuracy: 0.6629 - scaled_graph_loss: 0.0310 - val_loss: 1.2447 - val_accuracy: 0.6228\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.9270 - accuracy: 0.6486 - scaled_graph_loss: 0.0336 - val_loss: 1.2439 - val_accuracy: 0.6228\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.8997 - accuracy: 0.6629 - scaled_graph_loss: 0.0311 - val_loss: 1.2422 - val_accuracy: 0.6233\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.8918 - accuracy: 0.6851 - scaled_graph_loss: 0.0334 - val_loss: 1.2422 - val_accuracy: 0.6237\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.8790 - accuracy: 0.6782 - scaled_graph_loss: 0.0316 - val_loss: 1.2406 - val_accuracy: 0.6270\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.9034 - accuracy: 0.6729 - scaled_graph_loss: 0.0343 - val_loss: 1.2377 - val_accuracy: 0.6265\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.8774 - accuracy: 0.6759 - scaled_graph_loss: 0.0342 - val_loss: 1.2344 - val_accuracy: 0.6260\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.8690 - accuracy: 0.6675 - scaled_graph_loss: 0.0352 - val_loss: 1.2334 - val_accuracy: 0.6256\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.9060 - accuracy: 0.6741 - scaled_graph_loss: 0.0336 - val_loss: 1.2342 - val_accuracy: 0.6251\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.8555 - accuracy: 0.6816 - scaled_graph_loss: 0.0324 - val_loss: 1.2384 - val_accuracy: 0.6256\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.8771 - accuracy: 0.6856 - scaled_graph_loss: 0.0311 - val_loss: 1.2427 - val_accuracy: 0.6237\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.9016 - accuracy: 0.6545 - scaled_graph_loss: 0.0308 - val_loss: 1.2483 - val_accuracy: 0.6237\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.8224 - accuracy: 0.6916 - scaled_graph_loss: 0.0332 - val_loss: 1.2527 - val_accuracy: 0.6214\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.9124 - accuracy: 0.6560 - scaled_graph_loss: 0.0333 - val_loss: 1.2595 - val_accuracy: 0.6214\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.8134 - accuracy: 0.7029 - scaled_graph_loss: 0.0325 - val_loss: 1.2640 - val_accuracy: 0.6233\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.8572 - accuracy: 0.6986 - scaled_graph_loss: 0.0311 - val_loss: 1.2689 - val_accuracy: 0.6247\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.8083 - accuracy: 0.6929 - scaled_graph_loss: 0.0337 - val_loss: 1.2740 - val_accuracy: 0.6242\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.8370 - accuracy: 0.6851 - scaled_graph_loss: 0.0332 - val_loss: 1.2804 - val_accuracy: 0.6251\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.8938 - accuracy: 0.6659 - scaled_graph_loss: 0.0322 - val_loss: 1.2834 - val_accuracy: 0.6247\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.8821 - accuracy: 0.6755 - scaled_graph_loss: 0.0305 - val_loss: 1.2819 - val_accuracy: 0.6279\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.9084 - accuracy: 0.6201 - scaled_graph_loss: 0.0333 - val_loss: 1.2786 - val_accuracy: 0.6265\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.7901 - accuracy: 0.6955 - scaled_graph_loss: 0.0338 - val_loss: 1.2758 - val_accuracy: 0.6302\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.8072 - accuracy: 0.7073 - scaled_graph_loss: 0.0312 - val_loss: 1.2729 - val_accuracy: 0.6316\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.8399 - accuracy: 0.6681 - scaled_graph_loss: 0.0334 - val_loss: 1.2675 - val_accuracy: 0.6311\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.8823 - accuracy: 0.6903 - scaled_graph_loss: 0.0357 - val_loss: 1.2629 - val_accuracy: 0.6334\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.8458 - accuracy: 0.6832 - scaled_graph_loss: 0.0353 - val_loss: 1.2576 - val_accuracy: 0.6362\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.8244 - accuracy: 0.7133 - scaled_graph_loss: 0.0337 - val_loss: 1.2550 - val_accuracy: 0.6380\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.8125 - accuracy: 0.6952 - scaled_graph_loss: 0.0344 - val_loss: 1.2564 - val_accuracy: 0.6390\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.8262 - accuracy: 0.6795 - scaled_graph_loss: 0.0330 - val_loss: 1.2572 - val_accuracy: 0.6385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f20e9044bd0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_reg_model.fit(myTrain.batch(128), epochs=200, verbose=1, validation_data=myTest.batch(128),\n",
    "          callbacks=[TensorBoard(log_dir='/tmp/regularization')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9BHxcVj58Zrc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "03_Graph_regularization_graph_neural_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
